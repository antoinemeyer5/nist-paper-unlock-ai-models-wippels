
@inproceedings{wolf-etal-2020-transformers,
    title = "Transformers: State-of-the-Art Natural Language Processing",
    author = "Thomas Wolf and Lysandre Debut and Victor Sanh and Julien Chaumond and Clement Delangue and Anthony Moi and Pierric Cistac and Tim Rault and RÃ©mi Louf and Morgan Funtowicz and Joe Davison and Sam Shleifer and Patrick von Platen and Clara Ma and Yacine Jernite and Julien Plu and Canwen Xu and Teven Le Scao and Sylvain Gugger and Mariama Drame and Quentin Lhoest and Alexander M. Rush",
    booktitle = "Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations",
    month = oct,
    year = "2020",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://www.aclweb.org/anthology/2020.emnlp-demos.6",
    pages = "38--45"
}

@article {Stringer2020.02.02.931238,
	author = {Stringer, Carsen and Michaelos, Michalis and Pachitariu, Marius},
	title = {Cellpose: a generalist algorithm for cellular segmentation},
	elocation-id = {2020.02.02.931238},
	year = {2020},
	doi = {10.1101/2020.02.02.931238},
	publisher = {Cold Spring Harbor Laboratory},
	abstract = {Many biological applications require the segmentation of cell bodies, membranes and nuclei from microscopy images. Deep learning has enabled great progress on this problem, but current methods are specialized for images that have large training datasets. Here we introduce a generalist, deep learning-based segmentation algorithm called Cellpose, which can very precisely segment a wide range of image types out-of-the-box and does not require model retraining or parameter adjustments. We trained Cellpose on a new dataset of highly-varied images of cells, containing over 70,000 segmented objects. To support community contributions to the training data, we developed software for manual labelling and for curation of the automated results, with optional direct upload to our data repository. Periodically retraining the model on the community-contributed data will ensure that Cellpose improves constantly.},
	URL = {https://www.biorxiv.org/content/early/2020/02/03/2020.02.02.931238},
	eprint = {https://www.biorxiv.org/content/early/2020/02/03/2020.02.02.931238.full.pdf},
	journal = {bioRxiv}
}

@article{ravi2024sam2,
  title={SAM 2: Segment Anything in Images and Videos},
  author={Ravi, Nikhila and Gabeur, Valentin and Hu, Yuan-Ting and Hu, Ronghang and Ryali, Chaitanya and Ma, Tengyu and Khedr, Haitham and R{\"a}dle, Roman and Rolland, Chloe and Gustafson, Laura and Mintun, Eric and Pan, Junting and Alwala, Kalyan Vasudev and Carion, Nicolas and Wu, Chao-Yuan and Girshick, Ross and Doll{\'a}r, Piotr and Feichtenhofer, Christoph},
  journal={arXiv preprint arXiv:2408.00714},
  url={https://arxiv.org/abs/2408.00714},
  year={2024}
}




// AI MODAL CARDS

@COMMENT{MC_Google,
 title = {Google Paper},
 author = {Google},
 url = {https://modelcards.withgoogle.com/about}
}

@COMMENT{MC_Paper,
 title = {Model Cards for Model Reporting},
 author={Google},
 url = {https://dl.acm.org/doi/pdf/10.1145/3287560.3287596}
}

@COMMENT{MC_huggingFace,
 title = {Model Cards},
 author = {Hugging Face},
 url = {https://huggingface.co/docs/hub/en/model-cards}
}

@COMMENT{MC_BioImageIo,
 title = {Model Cards},
 author = {BioImage.IO},
 url = {https://bioimage.io/docs/#/bioimageio_model_spec}
}


@COMMENT{MC_Tensorflow,
 title = {Model Cards},
 author = {Tensorflow},
 url = {https://github.com/tensorflow/model-card-toolkit}
}
